{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5f39a9f-65c3-4209-b0e6-608eb1cba425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Крок 1: Імпорти та налаштування\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5850849-824b-4ebf-91ee-97e9dcb34825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "Ratings: (1149780, 3)\n",
      "Users: (278858, 3)\n",
      "\n",
      "Ratings Dataset Info:\n",
      "   User-ID        ISBN  Book-Rating\n",
      "0   276725  034545104X            0\n",
      "1   276726  0155061224            5\n",
      "2   276727  0446520802            0\n",
      "3   276729  052165615X            3\n",
      "4   276729  0521795028            6\n",
      "\n",
      "Rating range: 0 - 10\n",
      "Unique users: 105283\n",
      "Unique books: 340556\n"
     ]
    }
   ],
   "source": [
    "# Крок 2: Завантаження даних\n",
    "ratings_df = pd.read_csv('Ratings.csv')\n",
    "users_df = pd.read_csv('Users.csv')\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"Ratings: {ratings_df.shape}\")\n",
    "print(f\"Users: {users_df.shape}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nRatings Dataset Info:\")\n",
    "print(ratings_df.head())\n",
    "print(f\"\\nRating range: {ratings_df['Book-Rating'].min()} - {ratings_df['Book-Rating'].max()}\")\n",
    "print(f\"Unique users: {ratings_df['User-ID'].nunique()}\")\n",
    "print(f\"Unique books: {ratings_df['ISBN'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26f6fa37-3a92-4378-9fe0-3e62d8296454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "After removing 0 ratings: 433671 ratings\n",
      "After user filtering (min 6 ratings): 329336 ratings\n",
      "Active users: 12019\n",
      "After book filtering (min 10 ratings): 90929 ratings\n",
      "Popular books: 3966\n",
      "Original rating range: 1 - 10\n",
      "Normalized rating range: 1 - 5\n"
     ]
    }
   ],
   "source": [
    "# Крок 3: Попередня обробка\n",
    "def preprocess_data(ratings_df, min_ratings_per_user=6, min_ratings_per_book=10):\n",
    "    \"\"\"\n",
    "    Preprocess the ratings data by filtering and normalizing\n",
    "    \"\"\"\n",
    "    print(\"Starting data preprocessing...\")\n",
    "    \n",
    "    # Remove ratings with score 0 (implicit feedback, not actual ratings)\n",
    "    ratings_filtered = ratings_df[ratings_df['Book-Rating'] > 0].copy()\n",
    "    print(f\"After removing 0 ratings: {ratings_filtered.shape[0]} ratings\")\n",
    "    \n",
    "    # Filter users with minimum ratings\n",
    "    user_counts = ratings_filtered['User-ID'].value_counts()\n",
    "    active_users = user_counts[user_counts >= min_ratings_per_user].index\n",
    "    ratings_filtered = ratings_filtered[ratings_filtered['User-ID'].isin(active_users)]\n",
    "    print(f\"After user filtering (min {min_ratings_per_user} ratings): {ratings_filtered.shape[0]} ratings\")\n",
    "    print(f\"Active users: {len(active_users)}\")\n",
    "    \n",
    "    # Filter books with minimum ratings\n",
    "    book_counts = ratings_filtered['ISBN'].value_counts()\n",
    "    popular_books = book_counts[book_counts >= min_ratings_per_book].index\n",
    "    ratings_filtered = ratings_filtered[ratings_filtered['ISBN'].isin(popular_books)]\n",
    "    print(f\"After book filtering (min {min_ratings_per_book} ratings): {ratings_filtered.shape[0]} ratings\")\n",
    "    print(f\"Popular books: {len(popular_books)}\")\n",
    "    \n",
    "    # Normalize ratings from 1-10 to 1-5 scale\n",
    "    ratings_filtered['Book-Rating-Normalized'] = np.round(\n",
    "        (ratings_filtered['Book-Rating'] - 1) * 4 / 9 + 1\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Ensure ratings are within 1-5 range\n",
    "    ratings_filtered['Book-Rating-Normalized'] = np.clip(\n",
    "        ratings_filtered['Book-Rating-Normalized'], 1, 5\n",
    "    )\n",
    "    \n",
    "    print(f\"Original rating range: {ratings_filtered['Book-Rating'].min()} - {ratings_filtered['Book-Rating'].max()}\")\n",
    "    print(f\"Normalized rating range: {ratings_filtered['Book-Rating-Normalized'].min()} - {ratings_filtered['Book-Rating-Normalized'].max()}\")\n",
    "    \n",
    "    return ratings_filtered\n",
    "\n",
    "# Preprocess the data\n",
    "processed_ratings = preprocess_data(ratings_df, min_ratings_per_user=6, min_ratings_per_book=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ec1a946-58f4-46b7-99d5-4af1f80ec7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rating matrix...\n",
      "Matrix dimensions: 10309 users x 3966 books\n",
      "Matrix sparsity: 99.78%\n"
     ]
    }
   ],
   "source": [
    "# Крок 4: Створення User-Item матриці\n",
    "def create_user_item_matrix(ratings_df):\n",
    "    \"\"\"\n",
    "    Create user-item matrix for collaborative filtering\n",
    "    \"\"\"\n",
    "    # Create user and item mappings\n",
    "    unique_users = ratings_df['User-ID'].unique()\n",
    "    unique_books = ratings_df['ISBN'].unique()\n",
    "    \n",
    "    user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "    book_to_idx = {book: idx for idx, book in enumerate(unique_books)}\n",
    "    idx_to_user = {idx: user for user, idx in user_to_idx.items()}\n",
    "    idx_to_book = {idx: book for book, idx in book_to_idx.items()}\n",
    "    \n",
    "    print(f\"Matrix dimensions: {len(unique_users)} users x {len(unique_books)} books\")\n",
    "    \n",
    "    # Create the matrix\n",
    "    matrix = np.zeros((len(unique_users), len(unique_books)))\n",
    "    \n",
    "    for _, row in ratings_df.iterrows():\n",
    "        user_idx = user_to_idx[row['User-ID']]\n",
    "        book_idx = book_to_idx[row['ISBN']]\n",
    "        matrix[user_idx, book_idx] = row['Book-Rating-Normalized']\n",
    "    \n",
    "    # Calculate sparsity\n",
    "    sparsity = (matrix == 0).sum() / (matrix.shape[0] * matrix.shape[1]) * 100\n",
    "    print(f\"Matrix sparsity: {sparsity:.2f}%\")\n",
    "    \n",
    "    return matrix, user_to_idx, book_to_idx, idx_to_user, idx_to_book\n",
    "\n",
    "# Create matrix\n",
    "print(\"Creating rating matrix...\")\n",
    "rating_matrix, user_to_idx, book_to_idx, idx_to_user, idx_to_book = create_user_item_matrix(processed_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2598512a-4740-446c-bc8c-8177d4085d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 73962 ratings\n",
      "Test set: 16967 ratings\n"
     ]
    }
   ],
   "source": [
    "# Крок 5: Розділення даних\n",
    "def create_train_test_split(ratings_df, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split ratings data into train and test sets per user\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    for user_id in ratings_df['User-ID'].unique():\n",
    "        user_ratings = ratings_df[ratings_df['User-ID'] == user_id]\n",
    "        \n",
    "        if len(user_ratings) >= 6:  # Ensure enough ratings for split\n",
    "            train_user, test_user = train_test_split(\n",
    "                user_ratings, test_size=test_size, random_state=42\n",
    "            )\n",
    "            train_data.append(train_user)\n",
    "            test_data.append(test_user)\n",
    "        else:\n",
    "            train_data.append(user_ratings)\n",
    "    \n",
    "    train_df = pd.concat(train_data, ignore_index=True)\n",
    "    test_df = pd.concat(test_data, ignore_index=True) if test_data else pd.DataFrame()\n",
    "    \n",
    "    print(f\"Train set: {len(train_df)} ratings\")\n",
    "    print(f\"Test set: {len(test_df)} ratings\")\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# Split the data\n",
    "train_ratings, test_ratings = create_train_test_split(processed_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f629c00-bca8-49c0-8c4b-a3c33be53b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions: 10309 users x 3966 books\n",
      "Matrix sparsity: 99.82%\n",
      "Training SVD model...\n",
      "Model trained with 50 components\n",
      "Explained variance ratio: 0.1786\n"
     ]
    }
   ],
   "source": [
    "# Крок 6: SVD Recommender\n",
    "class SVDRecommender:\n",
    "    def __init__(self, n_components=50, random_state=42):\n",
    "        self.n_components = n_components\n",
    "        self.random_state = random_state\n",
    "        self.svd = TruncatedSVD(n_components=n_components, random_state=random_state)\n",
    "        self.user_mean = None\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, user_item_matrix):\n",
    "        \"\"\"\n",
    "        Train the SVD model\n",
    "        \"\"\"\n",
    "        print(\"Training SVD model...\")\n",
    "        \n",
    "        # Calculate user means for centering\n",
    "        self.user_mean = np.array([\n",
    "            row[row > 0].mean() if len(row[row > 0]) > 0 else 0 \n",
    "            for row in user_item_matrix\n",
    "        ])\n",
    "        \n",
    "        # Mean-center the matrix\n",
    "        centered_matrix = user_item_matrix.copy()\n",
    "        for i in range(len(centered_matrix)):\n",
    "            mask = centered_matrix[i] > 0\n",
    "            if mask.any():\n",
    "                centered_matrix[i][mask] -= self.user_mean[i]\n",
    "        \n",
    "        # Apply SVD\n",
    "        self.user_factors = self.svd.fit_transform(centered_matrix)\n",
    "        self.item_factors = self.svd.components_.T\n",
    "        \n",
    "        # Reconstruct the matrix\n",
    "        self.reconstructed = np.dot(self.user_factors, self.item_factors.T)\n",
    "        \n",
    "        # Add back user means\n",
    "        for i in range(len(self.reconstructed)):\n",
    "            self.reconstructed[i] += self.user_mean[i]\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        print(f\"Model trained with {self.n_components} components\")\n",
    "        print(f\"Explained variance ratio: {self.svd.explained_variance_ratio_.sum():.4f}\")\n",
    "        \n",
    "    def predict(self, user_idx, item_idx):\n",
    "        \"\"\"\n",
    "        Predict rating for a user-item pair\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model must be fitted before making predictions\")\n",
    "        \n",
    "        prediction = self.reconstructed[user_idx, item_idx]\n",
    "        return np.clip(prediction, 1, 5)  # Ensure prediction is within valid range\n",
    "    \n",
    "    def recommend_items(self, user_idx, user_item_matrix, n_recommendations=10):\n",
    "        \"\"\"\n",
    "        Recommend items for a user\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model must be fitted before making recommendations\")\n",
    "        \n",
    "        # Get user's ratings\n",
    "        user_ratings = user_item_matrix[user_idx]\n",
    "        \n",
    "        # Get items user hasn't rated\n",
    "        unrated_items = np.where(user_ratings == 0)[0]\n",
    "        \n",
    "        # Predict ratings for unrated items\n",
    "        predictions = []\n",
    "        for item_idx in unrated_items:\n",
    "            pred_rating = self.predict(user_idx, item_idx)\n",
    "            predictions.append((item_idx, pred_rating))\n",
    "        \n",
    "        # Sort by predicted rating\n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return predictions[:n_recommendations]\n",
    "\n",
    "# Create training matrix\n",
    "train_matrix, train_user_to_idx, train_book_to_idx, train_idx_to_user, train_idx_to_book = create_user_item_matrix(train_ratings)\n",
    "\n",
    "# Initialize and train the model\n",
    "recommender = SVDRecommender(n_components=50)\n",
    "recommender.fit(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c7c3a94-0e39-4f6a-a6bb-9bcda4a72939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "RMSE: 0.7720\n",
      "MAE: 0.5838\n",
      "Number of predictions: 16967\n"
     ]
    }
   ],
   "source": [
    "# Крок 7: Оцінка моделі\n",
    "def evaluate_model(recommender, test_ratings, train_user_to_idx, train_book_to_idx):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test data\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for _, row in test_ratings.iterrows():\n",
    "        user_id = row['User-ID']\n",
    "        book_isbn = row['ISBN']\n",
    "        actual_rating = row['Book-Rating-Normalized']\n",
    "        \n",
    "        # Check if user and book are in training data\n",
    "        if user_id in train_user_to_idx and book_isbn in train_book_to_idx:\n",
    "            user_idx = train_user_to_idx[user_id]\n",
    "            book_idx = train_book_to_idx[book_isbn]\n",
    "            \n",
    "            predicted_rating = recommender.predict(user_idx, book_idx)\n",
    "            predictions.append(predicted_rating)\n",
    "            actuals.append(actual_rating)\n",
    "    \n",
    "    if predictions:\n",
    "        rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "        \n",
    "        print(f\"Evaluation Results:\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"Number of predictions: {len(predictions)}\")\n",
    "        \n",
    "        return rmse, mae\n",
    "    else:\n",
    "        print(\"No valid predictions could be made\")\n",
    "        return None, None\n",
    "\n",
    "# Evaluate the model\n",
    "if not test_ratings.empty:\n",
    "    rmse, mae = evaluate_model(recommender, test_ratings, train_user_to_idx, train_book_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a6a54e7-eeeb-4a5a-8d86-58df8fe3d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Крок 8: ЗБЕРЕЖЕННЯ МОДЕЛІ ДЛЯ DJANGO\n",
    "model_data = {\n",
    "    'recommender': recommender,\n",
    "    'user_to_idx': train_user_to_idx,\n",
    "    'book_to_idx': train_book_to_idx,\n",
    "    'idx_to_user': train_idx_to_user,\n",
    "    'idx_to_book': train_idx_to_book,\n",
    "    'processed_ratings': processed_ratings,\n",
    "    'user_item_matrix': train_matrix\n",
    "}\n",
    "\n",
    "joblib.dump(model_data, 'svd_recommender_clean.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134cc95-30b7-45d4-872c-c2823e413ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
